name: Algolia DocSearch Crawler

on:
  workflow_dispatch:
  schedule:
    - cron: '10 5 * * SAT'

jobs:
  crawl:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write

    steps:
      - name: 检出仓库
        uses: actions/checkout@v4

      - name: 安装 jq
        run: sudo apt-get update && sudo apt-get install -y jq

      # 步骤 1：准备 DocSearch 配置
      # 使用 jq -c . 将 JSON 转为单行，并使用单引号确保内容被完全引用
      - name: 准备 DocSearch 配置
        id: prepare_config
        run: |
          # 使用 `printf %q` 来安全地引用 JSON 字符串，防止 shell 解析错误
          # 这是更健壮的 bash 引用方式，适用于复杂字符串
          CONFIG_JSON_QUOTED=$(jq -c . < algolia.config.json | xargs printf "%s")
          
          echo "--- Parsed CONFIG JSON (Quoted) ---"
          echo "$CONFIG_JSON_QUOTED"
          echo "-----------------------------------"
          # 将处理后的 JSON 设为步骤输出
          # GITHUB_OUTPUT 应该直接包含值，而不是再加引号，因为 docker run 的 -e 已经有引号了
          echo "config_output=${CONFIG_JSON_QUOTED}" >> "$GITHUB_OUTPUT"

      # 步骤 2：运行 DocSearch 爬虫 Docker 镜像
      - name: 运行 Algolia DocSearch 爬虫
        run: |
          docker run --rm \
            -e "APPLICATION_ID=${{ secrets.DOCSEARCH_APPLICATION_ID }}" \
            -e "API_KEY=${{ secrets.DOCSEARCH_API_KEY }}" \
            -e "CONFIG=${{ steps.prepare_config.outputs.config_output }}" \ # <-- 确保这里是双引号
            algolia/docsearch-scraper
